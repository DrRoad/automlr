#+TITLE: Automatic Machine Learning Algorithm Configuration in R
* Introduction
*automlr* is an R-package for *automatically* configuring *mlr* machine learning algorithms so that they perform well. It is designed for simplicity of use and supposed to run with minimal user intervention.
* Installation
/Note: Installation of automlr is currently only tested on Linux systems. Installation on other systems, especially Win32, might not work./

/Note 2: automlr integrates tightly with mlr, and I try to make it work with both the current CRAN version of mlr, as well as the version on github (https://github.org/mlr-org/mlr). mlr is a moving target, however, so if there are problems with the mlr version from github, try to fall back to the mlr version on CRAN./

automlr depends on *roxygen2* for installation, but roxygen2 is not listed in its dependencies, so make sure you have it installed:
#+BEGIN_SRC R
if (!require("roxygen2")) install.packages("roxygen2")
#+END_SRC
Then you can install automlr from source. automlr can work with many mlr learners; however, the respective dependent packages need to be installed for this. automlr doesn't /need/ these packages, but without them, the search space will be incomplete (and a warning will be given). To install automlr and all referenced learner packages (this can take a while!), do
#+BEGIN_SRC R
devtools::install_github("mlr-org/automlr", ref = "develop",
    dependencies = c("Depends", "Imports", "Suggests"))
#+END_SRC
to *only* install automlr (and the essential dependencies), do
#+BEGIN_SRC R
devtools::install_github("mlr-org/automlr", ref = "develop")
#+END_SRC

To use the "mbo" backend, automlr relies on *mlrMBO*, which itself relies on a *ParamHelpers* version that is not on CRAN yet. To install these, run
#+BEGIN_SRC R
devtools::install_github("berndbischl/ParamHelpers")
devtools::install_github("mlr-org/mlrMBO")
#+END_SRC
* Usage
To run a small example to fit some learners on the mlr-provided ~pid.task~, execute
#+BEGIN_SRC R
library("mlr")
library("automlr")
configureMlr(on.learner.error = "warn", show.learner.output = FALSE)
amrun = automlr(pid.task, backend = "random", budget = c(evals = 10))
result = amfinish(amrun)
print(result, verbose = TRUE)
#+END_SRC
This already shows all the mandatory arguments of ~automlr~: The task for which to optimize, the backend to use (may be "random", "irace" or "mbo"), and a computational budget. The resulting object can be given to another ~automlr~ call with a different budget to continue optimizing, or to ~amfinish~ to finalize the run.

The functions and data exported by automlr that will be of interest to the user:
- automlr invocation
  - automlr :: The main entry point; can be called with a task and a backend, or with an object that was returned by a previous automlr invocation, or even with a file name that was used by automlr to save the state. The user can choose:
    - which backend to use (~backend~)
    - the computational budget (~budget~)
    - a possible savefile (~savefile~) and the interval in which to save to a file (~save.interval~)
    - a measure for which to optimize, if not the task's default measure (~measure~)
  - amfinish :: Generates an ~AMResult~ object that contains information about the optimization result.
  - mlrLearners, mlrLearnersNoWrappers :: A collection of mlr learners with corresponding search space. ~mlrLearnersNoWrappers~ does not contain preprocessing wrappers.
  - mlrLightweight, mlrLightweightNoWrappers :: Similar to ~mlrLearners~ and ~mlrLearnersNoWrappers~, these are search spaces with the slowest learners removed. This decreases evaluation time and is also necessary for the "mbo" backend to work.
- searchspace definition
  - autolearner :: define your own mlr learner to put in a search space
  - autoWrapper :: define an mlr wrapper to use in a search space
  - sp :: for defining parameters that are given to ~autolearner~
See their respective R documentation for more information and additional arguments.

* Project status
Currently the project is undergoing heavy development; while the spirit of the application is expected to be stable, the user interface may undergo slight changes in the future. Expect the internals of automlr to be changing regularly.

** Notes
- the "irace" backend's behaviour deviates slightly from that of the ~irace~ package in so far that the number of evaluations per generation, and the slimming of the sampling distribution, are independent of the budget.
- the "mbo" backend currently uses an inferior imputation method for the surrogate model, and its performance should not be seen as representative for ~mlrMBO~.

** Project TODO
(under consideration, subject to change)
- [-] release 0.1
  - [X] write preliminary readme
  - [-] Tests pass
    - [X] backend tests
    - [ ] realworld tests
  - [X] adapt coding style to mlrOrg
  - [X] write documentation for entry points
  - [X] Adapt entry point docu to mlrOrg style
  - [X] finish writing wrappers
  - [X] correct version dependencies 
  - [X] argument for debug level
  - [X] package build generate mlrLearners.R
  - [X] automatically recognize absence of learner package and skip
  - [X] DESCRIPTION Suggests should really contain all learner packages of mlr.
  - [X] patch bugs in CRAN-versions of ParamHelpers and mlr
  - [X] mlrLearners, mlrLearnersNoWrap variables
  - [X] write NEWS
- [ ] release 0.2
  - [ ] instead of backend string, accept backend objects that carry optimization arguments specific to the backend
  - [ ] event handling
    - [ ] catch Ctrl-C and handle gracefully
    - [ ] maximum walltime overrun
    - [ ] make sure mlr on.learner.error, on.learner.warning are handled well
    - [ ] nicer printing
  - [ ] make debugging easier
    - [ ] debug flag sets all show.learner.output to TRUE
    - [ ] optionally sets some variables to small values (thinking of you, ~infill.opt.focussearch.points~) so do.call doesn't clog the call stack so much
  - [ ] searchspace
    - [ ] add metalearner wrappers
    - [ ] respect parameter equality IDs
    - [ ] automatically recognize absence of learner (in a hypothetical future mlr version) and don't throw an error
    - [ ] searchspace definitions for certain mlr versions
  - [ ] tests
    - [ ] differentiate expensive tests from fast tests
    - [ ] 100% test coverage
    - [ ] tests for preprocessing
    - [ ] test for all possible wrong arguments
    - [ ] other things?
  - [ ] simultaneous multiple task optimization
  - [ ] write a nicer readme **selfconscious**
  - [ ] parallelMap is not required as dependency, make it optional.
- [ ] release 0.3
  - [ ] regression learners
  - [ ] task property transformation by wrappers (e.g. recognize a wrapper converts factors to numerics and allow numerics learners)
  - [ ] use seeds in learners that use external RNGs
  - [ ] installation on Win32
  - [ ] more consistent OO-based searchspace definition
  - [ ] more empirical grounding for mlrLightweight.
- [ ] release 0.4
  - [ ] other backends?
  - [ ] batchJobs integration? (e.g. break run down into smaller jobs)
  - [ ] priors for learners?
- [ ] release 1.0
  - [ ] everything is really, really stable
